1. Input: 'addNode'
    - ECS SSHs to start a KVServer process at the specified port and address from the config file
        - Creates a ZooKeeper node with its server name under /servers
        - The starting state is 'BOOT'
        - The ECS server has a watcher for the getChildren
        - It notices that a new child was created (since state == 'BOOT'):
            - Subscribes to this new zk node
    - Gets added to the pending start & active_servers (since we need it for the hash ring)
2. Input: 'start'
    - For each server in pendingStart:
        - Check if any move has to take place, and starts COPYING the data over to the newly created server:
            - Lock the server
            - Delete the COPIED data
            - Unlock the server
            - Send 'MOVE_COMPLETE' event to the ECS indicating that the MOVE was complete
        - Send a 'START' event
    - Once all the moves have happened (we received an equal number of ACK's), update the ECS METADATA,
    since the newly started server(s) are now running and can serve requests
    - Broadcast the metadata to all the active servers, even the newly added ones (since data might be stale)
3. Input: 'removeNode'
    - For the soon-to-deleted server:
        - Lock the server
        - Move the data from the server to the successor server
        - Once the move is complete, delete the files and storage directory
    - Once completed, it will shutdown its ZooKeeper instance
    - The ECS Server will notice the absence of the zk node and will then update its internal METADATA
    - Then, the ECS Server will broadcast the updated metadata to all the servers
    - Finally, add that deleted server back to the list of available servers

* To avoid any problems with pendingStarts, we will not allow the user to add any new nodes until after the 
previously created nodes have been fully started AND any nodes have been removed. 
We can verify this by ensuring that pendingStart && movedServers == 0
* Also, no deleting servers while another deletion is happening

- Edge cases:
    -
        - We add a server, then we calc its metadata, but don't update OUR internal metadata
        - We add another server (but don't start the previous server yet) and since the internal metadata is stale
        there will be a conflict
        - Solve it only updating the treemap metadata, but not the raw metadata, and recalculating and updating the
        previously added, but not started nodes (pendingStart) 
    - While the ECS was busy, requests could come in. What then?
    - There is a remove AFTER there has been a server added (must update the previously added server?)
    - What do we do about the data that is already there? Do we move it somewhere upon server start?

Simple to do test cases:
1. Adding more servers than the limit
    1.1 Do it all at once first: addNodes 8
    1.2 Then do it incrementally: addNode, addNode, addNode, ...
    1.3 Then try combining it: addNodes 6, addNode, addNode